# Appendix A. Project Methods {-}

## Selecting Participating Refuges

The national visitor survey was conducted from March 2018 to April 2019 on 37 refuges across the Refuge System (tab:refuge-list). Each refuge was selected for participation by regional office Visitor Services Chiefs.

Table: (\#tab:refuge-list)
```{r refuge-list, echo=FALSE, tab.cap="Refuges sampled during the 2018 national wildlife refuge survey"}
```

| **Refuges** | 
| --- |
| **Pacific Region (R1)** | 
| Billy Frank Jr. Nisqually NWR (WA)<br>Dungeness NWR (WA)<br>Guam NWR (GU)<br>Hanalei NWR (HI)<br>Kilauea Point NWR (HI)<br>Ridgefield NWR (WA)<br>Steigerwald Lake NWR (WA)<br>Tualatin River NWR (OR) |
| **Southwest Region (R2)** |
| Balcones Canyonlands NWR (TX)<br>  Hagerman NWR (TX) |
| **Midwest Region (R3)** | 
| Crab Orchard NWR (IL)<br> Loess Bluffs NWR (MO)<br> Ottawa NWR (OH)<br>  Sherburne NWR (MN)<br> Shiawassee NWR (MI) |
| **Southeast Region (R4)** | 
| A.R.M. Loxahatchee NWR (FL)<br> Bayou Sauvage NWR (LA)<br> Big Branch Marsh NWR (LA)<br> Cache River NWR (AR)<br> J.N. Ding Darling NWR (FL)<br> Okefenokee NWR (GA)<br> Pinckney Island NWR (SC)<br> Sam D. Hamilton Noxubee NWR (MS)<br> Tennessee NWR (TN) |
| **Northeast Region (R5)** | 
| Blackwater NWR (MD)<br> Canaan Valley NWR (WV)<br> Great Meadows NWR (MA)<br> John Heinz NWR at Tinicum (PA)<br> Ohio River Islands NWR (PA)<br> Prime Hook NWR (DE)<br> Sachuest Point NWR (RI) |
| **Mountain-Prairie Region (R6)** | 
| Kirwin NWR (KS)<br> Rainwater Basin WMD (NE)<br> Sullys Hill National Game Preserve (ND) |
| **Alaska Region (R7)** | 
| None in 2018 |
| **Pacific Southwest Region (R8)** | 
| Desert NWR (NV)<br> San Diego NWR (CA)<br> San Diego Bay NWR (CA) |


## Developing the Survey Instrument

Researchers at OSU developed the survey in consultation with the Service Headquarters Office, managers, planners, and visitor services professionals. The survey was peer-reviewed by academic and government researchers. The survey and associated methodology were approved by the Office of Management and Budget (OMB control #: 0596-0236; expiration date: 11/30/2020).

## Contacting Visitors

Refuge staff identified two separate 14-day sampling periods, and one or more locations at which to sample, that best reflected the diversity of use and specific visitation patterns of each participating refuge. A standardized sampling schedule was created for all refuges that included eight randomly selected sampling shifts during each of the two sampling periods. Sampling shifts were four (hr) time bands, stratified across AM and PM as well as weekend and weekdays. In coordination with refuge staff, any necessary customizations were made to the standardized schedule to accommodate the identified sampling locations and to address specific spatial and temporal patterns of visitation.

Twenty visitors (18 years of age or older) per sampling shift were systematically selected, for a total of 400 willing participants per refuge (or 200 per sampling period) to ensure an adequate sample of completed surveys. When necessary, shifts were moved, added, or extended to alleviate logistical limitations (for example, weather or low visitation at a particular site) in an effort to reach target numbers.

American Conservation Experience Interns and/or USFWS Human Dimensions staff (survey recruiters) contacted visitors onsite following a protocol provided by OSU that was designed to obtain a representative sample. Instructions included contacting visitors across the entire sampling shift (for example, every nth visitor for dense visitation, as often as possible for sparse visitation) and contacting only one person per group. Visitors were informed of the survey effort, given a token incentive (for example, a small magnet or temporary tattoo), and asked to participate. Willing participants provided their name, mailing address, and preference for language (English or Spanish). Survey recruiters were also instructed to record any refusals and then proceed with the sampling protocol



All visitors that agreed onsite to fill out a survey received the same sequence of correspondence. This approach allowed for an assessment of visitors&#39; likelihood of completing the survey by their preferred survey mode [@sexton2011]. Researchers at OSU sent the following materials to all visitors agreeing to participate who had not yet completed a survey at the time of each mailing [@dillman2014]:

- A postcard mailed within 10 days of the initial onsite contact thanking visitors for agreeing to participate in the survey and inviting them to complete the survey online.
- A packet mailed 14 days later consisting of a cover letter, survey, and postage paid envelope for returning a completed paper survey.
- A reminder postcard mailed 14 days later.
- A second packet mailed 7 days later consisting of another cover letter, survey, and postage paid envelope for returning a completed paper survey.

Each mailing included instructions for completing the survey online, so visitors had an opportunity to complete an online survey with each mailing. Those visitors indicating a preference for Spanish were sent Spanish versions of all correspondence (including the survey). Online survey data were exported and paper survey data were entered into Microsoft Excel using a standardized survey codebook and data entry procedure. All survey data were analyzed using _Statistical Package for the Social Sciences_ (SPSS, v.23) and R software^[Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.].

## Interpreting the Results

The extent to which these results accurately represent the total population of visitors to this refuge is dependent on the number of visitors who completed the survey (sample size) and the ability of the variation resulting from that sample to reflect the beliefs and interests of different visitor user groups (Scheaffer and others, 1996). The composition of the sample is dependent on the ability of the standardized sampling protocol for this study to account for the spatial and temporal patterns of visitor use unique to each refuge. Spatially, the geographical layout and public-use infrastructure varies widely across refuges. Some refuges can be accessed only through a single entrance, while others have multiple unmonitored access points across large expanses of land and water. As a result, the degree to which sampling locations effectively captured spatial patterns of visitor use will vary from refuge to refuge. Temporally, the two 14-day sampling periods may not have effectively captured all of the predominant visitor uses/activities on some refuges during the course of a year, which may result in certain survey measures such as visitors&#39; self-reported &quot;primary activity during their visit&quot; reflecting a seasonality bias. Results contained within this report may not apply to visitors during all times of the year or to visitors who did not visit the survey locations.

In this report, visitors who responded to the survey are referred to simply as &quot;visitors.&quot; However, when interpreting the results for `r paste(params$RefugeName)`, any potential spatial and temporal sampling limitation specific to this refuge needs to be considered when generalizing the results to the total population of visitors. For example, a refuge that sampled during a special event (for example, birding festival) held during the spring may have contacted a higher percentage of visitors who traveled greater than 50 miles (mi) to get to the refuge than the actual number of these people who would have visited throughout the calendar year (that is, oversampling of nonlocals). Another refuge may not have enough nonlocal visitors in the sample to adequately represent the beliefs and opinions of that group type. If the sample for a specific group type (for example, nonlocals, hunters, visitors who paid a fee) is too low (_n_ \&lt; 30), a warning is included in the text. Finally, the term &quot;this visit&quot; is used to reference the visit during which people were contacted to participate in the survey.

## Non-Response Bias
Non-response bias is the bias that results when respondents differ in meaningful ways from nonrespondents. Non-response bias affects the ability to generalize survey results, to some degree and in some ways, from the sample to the studyâ€™s target population [@dillman2014, @salant1994]. If non-respondents are found to differ from respondents in meaningful ways, care should be taken when interpreting survey responses, as they may overrepresent some segments of the target population to some degree, and may under-represent other segments of the population to some degree.

To check for non-response bias, this study used answers to three non-response bias questions and three observable characteristics of the contacted visitor to compare respondents with nonrespondents. The following questions and observations were used for evaluation of non-response bias:
- What is your primary activity at the refuge today?
- Do you live within 50 miles of this refuge?
- What year were you born?

In addition to the three non-response bias questions, the following three characteristics were observed and recorded:
- Gender of the person in the group who was first contacted by the survey recruiter
- Number of adults (18 years and older) in the group
- Number of children (under 18 years) in the group

Ideally, responses or observed estimates for non-response bias variables should be collected from all respondents and non-respondents. The collection of information from all contacted individuals provides the best comparison of characteristics between the respondent and non-respondent populations. More practically, a majority of responses or observed estimates must be present to adequately characterize both the respondent and non-respondent populations. In this study, 70% was identified as the minimum percentage of valid values for non-response variables needed for both respondent and non-respondent populations in order to adequately characterize the populations on a given non-response variable. All non-response variables met the minimum for 70% valid values among respondents and/or non-respondents \@ref(tab:nonresponse). Correspondingly, all variables were used for non-response bias analysis.

Table: (\#tab:nonresponse) Number and percentage of respondents and non-respondents with valid values for nonresponse variable

| **Variable** | **Respondents** |**Non-Respondents**|
| --- | --- | --- |
| Gender | x | y |
| Number of Adults | x | y |
| Number of Children | x | y |
